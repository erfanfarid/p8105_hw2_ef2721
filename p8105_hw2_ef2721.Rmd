---
title: "p8105_hw2_ef2721"
author: "Erfan Faridmoayer"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r}
library(tidyverse)
library(readxl)
```


## Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. First data is imported, then the `Route` column names that are not `dbl` are turned into `chr`. We then use janitor function, select the noted columns, and change `entry` from `yes` / `no` to a logical variable. 

```{r}
trans_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

The presentation is not yet "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_df %>% 
  select(station_name, line) %>% 
  distinct
```

There are 465 unique stations based on the code chunk above. 

To identify unique stations that are `ada` complaints, we first filter the data from ada that are `TRUE`. Then, similar to above, we select based on station name and line. Below is the code chunk explanation.

```{r}
trans_df %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

There are 84 compliant stations.

For the next sub-question, we first filter the stations with no vending machine. We then see how many stations from that subset allow entry to be possible. Mean is proportion here since entry is a logical variable. 

```{r}
trans_df %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

the proportion desired was 0.38.

We use the `pivot_longer` function to reformat the data to add route number and route name as distinct variables. Subsequently, we use the `filter` function to narrow down which stations service A line, and of those which are ADA compliant, respectively. The code chunk below addresses that 

```{r}
trans_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

There are 60 distinct stations that serve the A line

```{r}
trans_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

There are 17 distinct stations which serve the A line and are ADA compliant.

## Problem 2

The `readxl` library has been introduced earlier in the code. In this problem, we first read the data, narrowing to the sheet desired. To avoid unnecessary images, the data were selected to the numerical table. 

We then use the `janitor` function to clean the data, and selected dumpster-specific data. Using the `filter` function, the rows with summary values were removed. The `as.integer` function was used to round sports_balls values to the nearest round number. Lastly, `mutate` was used to move the column with titles to the beginning of the data set, and to change `year` to the _double_ variable.

Below, is the code chunk implementing above:

```{r}
trash_df =
  read_excel("./data/Trash Wheel Collection Data.xlsx", 
      sheet = "Mr. Trash Wheel", 
      range = "A2:N549") %>% 
  janitor::clean_names() %>% 
  select(-homes_powered) %>% 
  drop_na %>% 
  mutate(
    sports_balls = as.integer(sports_balls)
  ) %>% 
  mutate(
    dumpster = as.integer(dumpster)
  ) %>% 
  mutate(
    trash_source = "mr_trash_wheel",
    .before = dumpster) %>% 
  mutate(
    year = as.double(year)
  )
```

Of note, add the end of the code-chunk above, the `mutate` function was used to add a column at the beginning of the dataframe to distinguish source of data. We will now use a similar approach to import and clean the data from "Professor Trash Wheel". Please see the code-chunk below:

```{r}
protrash_df = 
  read_excel("./data/Trash Wheel Collection Data.xlsx",
      sheet = "Professor Trash Wheel",
      range = "A2:M96") %>%
  janitor::clean_names() %>%
  select(-homes_powered) %>%
  drop_na %>% 
  mutate(
    dumpster = as.integer(dumpster)
  ) %>% 
  mutate(
    trash_source = "prof_trash_wheel",
    .before = dumpster)
```

In each dataframe, the "dumpster" variable contained  different types. As such, both were turned into integers using `as.integer` function.

Now, both data frames are ready to be added together. We will do so in the code chunk below:

```{r}
alltrash_df =
  bind_rows(trash_df, protrash_df) %>% 
  janitor::clean_names()
```

The result of the code chinks above is a dataframe called "alltrash_df", which was created using the `readxl` package. There are a total of **`r nrow(alltrash_df)`** observations in this dataframe, **`r nrow(trash_df)`** of which belong to the _Mr. Trash Wheel_ dataset. The average weight of the trash in _Mr. Trash Wheel_ was **`r mean(trash_df$weight_tons)` tons** and, in _Professor Trash Wheel_ was **`r mean(protrash_df$weight_tons)` tons**. The total weight of trash collected by _Professor Trash Wheel_ was **`r sum(protrash_df$weight_tons)` tons**. The total number of sports balls collected by _Mr. Trash Wheel_ in 2020 was **856 balls**.


## Problem 3

### Part 1
In the code chunk below, we imported the _pols-month_ dataset into the `pol_df` dataframe. We then cleaned it up using `janitor`, then split the dates into their year, month, and day components using `separate()` argument, splitting by _"-"_. 

The month number was then converted to written using `month.name` function. Afterward, the president column was created with `mutate()` utilizing the `prez_gop` and `prez_dem` columns. The `if_else` function was used to define values of the two available conditions, using `gop` and `dem` values, respectively. 

Lastly, the `prez_gop`, `prez_dem`, and `day` columns were removed using the `select()` function.

```{r}
pol_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(
    mon, 
    into = c("year", "month", "day"), 
    sep = "-", 
    convert = TRUE) %>% 
  mutate(month = month.name[month]) %>% 
  mutate(president = prez_gop - prez_dem) %>% 
  mutate(president = if_else(president <0, "dem", "gop")) %>% 
  select(-prez_gop, -prez_dem, -day) %>% 
  select(year, month, president, everything())
```


### Part 2
Next, in the following code chunk, we imported and cleaned the `snp.csv` file using the `read_csv` and `janitor::clean_names()` functions. we then separated the date into 3 columns. 

The order here, however, was different than the previous chunk. So, we followed an _MDY_ model. In order to change the dates from 2-digits into 4 digits, an additional conditional variable was created, and `mutate()` function was used to differentiate centuries based on relation to current year 22. 

The columns were then sorted by year and month using `arrange()` function. For consistency, month was changed from numerical to written description. Lastly, using  `select()`, the intermediate variables and date columns. were removed.

```{r}
snp_df =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(
    date, 
    into = c("month", "date", "dig_2_year"), 
    sep = "/", 
    convert = TRUE) %>% 
  mutate(alter = if_else(dig_2_year < 22, "2000", "1900")) %>% 
  mutate(alter = as.integer(alter)) %>% 
  mutate(year = alter + dig_2_year, .before = month) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month]) %>% 
  select(-dig_2_year, -alter, -date)
```


### Part 3
Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

In this code-chunk, the _unemployment_ database was first read by the `read.csv` function, placed into the _unemp_df_ dataframe, and was then cleaned using the `janitor` package. Subsequently, the _unemp_tidy_df_ dataframe was introduced to utilize the `pivot_longer` function, to associate the months with each year through the new `month` variable and the unemployment rates to the new `unemployment_rate` column. 

Lastly, for consistency, `mutate` function was used to capitalize the first month letters, followed by the `month.name` function to to expand the 3-letter `month.abb` values.

```{r}
unemp_df = 
  read.csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names()

Unemp_tidy_df = 
  pivot_longer(
    unemp_df, 
    jan:dec,
    names_to = "month", 
    values_to = "unemployment_rate") %>% 
    mutate(month = str_to_title(month)) %>% 
    mutate(month = month.name[match(month, month.abb)])
```



